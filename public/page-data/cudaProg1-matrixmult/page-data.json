{
  "componentChunkName": "component---src-templates-blog-post-js",
  "path": "/cudaProg1-matrixmult/",
  "webpackCompilationHash": "",
  "result": {
    "data": {
      "site": {
        "siteMetadata": { "title": "FANG'S NOTEBOOK", "author": "Fang Cabrera" }
      },
      "markdownRemark": {
        "id": "0844d5dd-0ad9-5c49-9f9a-c3f9bd37eaf9",
        "excerpt": "Notation Matrix  Matrix  Output Matrix  row counter:  column counter:   is the element at   position in the vertical direction and…",
        "html": "<h2>Notation</h2>\n<ul>\n<li>Matrix <code class=\"language-text\">M</code></li>\n<li>Matrix <code class=\"language-text\">N</code></li>\n<li>Output Matrix <code class=\"language-text\">P</code></li>\n<li>row counter: <code class=\"language-text\">i</code></li>\n<li>column counter: <code class=\"language-text\">j</code></li>\n<li><code class=\"language-text\">P(Row, Col)</code> is the element at <code class=\"language-text\">Row-th</code> position in the vertical direction and <code class=\"language-text\">Col-th</code> position in the horizontal direction</li>\n</ul>\n<p>As shown in the picture below, <code class=\"language-text\">P(Row,Col)</code> (the small square in P) is the inner product of:</p>\n<ul>\n<li>the <code class=\"language-text\">Row-th</code> row of M</li>\n<li>the <code class=\"language-text\">Col-th</code> column of N</li>\n</ul>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/832d47291d72e9a03f794315730c528c/7377b/matmult.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 93.02083333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAMFAQIE/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAABv+bMJGCx1AD/xAAbEAEBAAEFAAAAAAAAAAAAAAABAAIDEBESIf/aAAgBAQABBQK1Zs312QZxOOuN/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGBAAAwEBAAAAAAAAAAAAAAAAACExECD/2gAIAQEABj8C4eMhD//EABwQAAICAgMAAAAAAAAAAAAAAAABETEhYUFRcf/aAAgBAQABPyEuvCXEDoXQ2w2+pKQmSWBqn//aAAwDAQACAAMAAAAQ88A8/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHRABAAICAgMAAAAAAAAAAAAAAQARMUEhYVGh4f/aAAgBAQABPxCZfaC5grZCOB6P2W0oHJbFPFGm6nsUI+zG6lwXh8T/2Q=='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"matmul\"\n        title=\"\"\n        src=\"/static/832d47291d72e9a03f794315730c528c/1697e/matmult.jpg\"\n        srcset=\"/static/832d47291d72e9a03f794315730c528c/a2cfd/matmult.jpg 148w,\n/static/832d47291d72e9a03f794315730c528c/3348f/matmult.jpg 295w,\n/static/832d47291d72e9a03f794315730c528c/1697e/matmult.jpg 590w,\n/static/832d47291d72e9a03f794315730c528c/6a00a/matmult.jpg 885w,\n/static/832d47291d72e9a03f794315730c528c/7377b/matmult.jpg 960w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </span>\n  </a></p>\n<h2>Indexing</h2>\n<p>The row index for the P element is:</p>\n<p><code class=\"language-text\">Row = blockIdx.y * blockDim.y + threadIdx.y</code></p>\n<p>The column index for the P element is:</p>\n<p><code class=\"language-text\">Col = blockIdx.x * blockDim.x + threadIdx.x</code></p>\n<p>With this one-to-one mapping, the <code class=\"language-text\">Row</code> and <code class=\"language-text\">Col</code> thread indexes are also the row and column indexes for output array</p>\n<h2>Simple Kernel Using One Thread</h2>\n<p>Note that the <code class=\"language-text\">Width</code> used below is the <code class=\"language-text\">Width</code> in the picture above.</p>\n<div class=\"gatsby-highlight\" data-language=\"c\"><pre class=\"language-c\"><code class=\"language-c\">__global__ <span class=\"token keyword\">void</span> MatrixMulKernel <span class=\"token punctuation\">(</span><span class=\"token keyword\">float</span><span class=\"token operator\">*</span> M<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span><span class=\"token operator\">*</span> N<span class=\"token punctuation\">,</span> <span class=\"token keyword\">float</span><span class=\"token operator\">*</span> P<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> Width<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// calculate the row index of the P element and M</span>\n    <span class=\"token keyword\">int</span> Row <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>y <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>y <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">;</span>\n    <span class=\"token comment\">// calculate the col index of the P element and N</span>\n    <span class=\"token keyword\">int</span> Col <span class=\"token operator\">=</span> blockIdx<span class=\"token punctuation\">.</span>x <span class=\"token operator\">*</span> blockDim<span class=\"token punctuation\">.</span>x <span class=\"token operator\">+</span> threadIdx<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>Row <span class=\"token operator\">&lt;</span> Width<span class=\"token punctuation\">)</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">(</span>Col <span class=\"token operator\">&lt;</span> Width<span class=\"token operator\">></span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">float</span> Pvalue <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n        <span class=\"token comment\">//each thread computes one element of the block sub-matrix</span>\n        <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> k <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> k <span class=\"token operator\">&lt;</span> Width<span class=\"token punctuation\">;</span> k<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            Pvalue <span class=\"token operator\">+</span><span class=\"token operator\">=</span> M<span class=\"token punctuation\">[</span>Row<span class=\"token operator\">*</span>Width <span class=\"token operator\">+</span> k<span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> N<span class=\"token punctuation\">[</span>k<span class=\"token operator\">*</span>Width <span class=\"token operator\">+</span> Col<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n        <span class=\"token punctuation\">}</span>\n        P<span class=\"token punctuation\">[</span>Row <span class=\"token operator\">*</span> Width <span class=\"token operator\">+</span> Col<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> Pvalue<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h4>memory access of the for loop</h4>\n<p>In every iteration of the loop, <strong>two global memory accesses</strong> are performed for one floating-point multiplication and one floating-point addition.</p>\n<h5>memory accesses</h5>\n<ul>\n<li>One global memory access fetches an M element</li>\n<li>the other fetches an N element</li>\n</ul>\n<h5>computation performed</h5>\n<ul>\n<li>One floating-point operation multiplies the M and N elements fetched</li>\n<li>the other accumulates the product into Pvalue</li>\n</ul>\n<h5>compute-to-global-memory-access ratio</h5>\n<p>The <strong>compute-to-global-memory-access ratio</strong> of the loop is 1.0.</p>\n<p>This ratio will likely result in less than 2% utilization of the peak execution speed of the modern GPUs.</p>\n<p>We need to increase the ratio by at least an order of magnitude for the computation throughput of modern devices to achieve good utilization.</p>\n<h2>Execution of the Matrix Multiplication Kernel Within A Block</h2>\n<h4>setting</h4>\n<ul>\n<li>\n<p>size of <code class=\"language-text\">P</code> is 4×4</p>\n</li>\n<li>\n<p><code class=\"language-text\">BLOCK_WIDTH = 2</code></p>\n</li>\n</ul>\n<h4>map threads to P</h4>\n<p>With:</p>\n<ul>\n<li>blocks that are 2×2 arrays of threads</li>\n<li>each thread calculating one P element</li>\n</ul>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/80715c267350989128c917d4d67a1a69/61cf7/execution.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 93.19526627218934%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAIDAQX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAH25vA3B2QgH//EABsQAAIDAAMAAAAAAAAAAAAAAAEhAAIREjEy/9oACAEBAAEFAlORgYxSnVlUeQTn/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGBAAAgMAAAAAAAAAAAAAAAAAADEBECD/2gAIAQEABj8CVyPP/8QAHBAAAgEFAQAAAAAAAAAAAAAAAAEhETFBUXHB/9oACAEBAAE/IbMacFAqG4xquBr2XMyO2NE2M4f/2gAMAwEAAgADAAAAELMHAP/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8QH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8QH//EAB4QAQEAAgICAwAAAAAAAAAAAAERAFEhQTFxgaHB/9oACAEBAAE/EEr0LQ+mCKYlqly6IooimSK8rWsAOPR6a9ZteXnFFieH5x0IUvRrIv4M/9k='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"execution\"\n        title=\"\"\n        src=\"/static/80715c267350989128c917d4d67a1a69/1697e/execution.jpg\"\n        srcset=\"/static/80715c267350989128c917d4d67a1a69/a2cfd/execution.jpg 148w,\n/static/80715c267350989128c917d4d67a1a69/3348f/execution.jpg 295w,\n/static/80715c267350989128c917d4d67a1a69/1697e/execution.jpg 590w,\n/static/80715c267350989128c917d4d67a1a69/61cf7/execution.jpg 676w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </span>\n  </a></p>\n<p>The P matrix is now divided into four tiles, and each block calculates one tile.</p>\n<ul>\n<li>In the example, <code class=\"language-text\">thread(0,0)</code> of <code class=\"language-text\">block(0,0)</code> calculates <code class=\"language-text\">P(0,0)</code></li>\n<li><code class=\"language-text\">thread(0,0)</code> of <code class=\"language-text\">block(1,0)</code> calculates <code class=\"language-text\">P(2,0)</code></li>\n</ul>\n<h4>actions of one thread block</h4>\n<p>The picture below illustrates the multiplication operations in each thread block.</p>\n<p>Threads in block (0,0) produce four dot products.</p>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/f4f50/block.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 97.9320531757755%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAEFAgMG/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAHoKTfjm2g1IkJB/8QAGxAAAQQDAAAAAAAAAAAAAAAAAAECAwQUIDL/2gAIAQEAAQUCL3ZlKTP1/8QAFREBAQAAAAAAAAAAAAAAAAAAASD/2gAIAQMBAT8BRj//xAAWEQADAAAAAAAAAAAAAAAAAAABAiD/2gAIAQIBAT8BDR//xAAdEAABAgcAAAAAAAAAAAAAAAABAAIQERIgMkGh/9oACAEBAAY/Ak2GPE00AzGxb//EABsQAAICAwEAAAAAAAAAAAAAAAABEbEQIDFh/9oACAEBAAE/IStePQJm6GPrGiP/2gAMAwEAAgADAAAAEAAIAP/EABYRAAMAAAAAAAAAAAAAAAAAAAEgMf/aAAgBAwEBPxAKp//EABYRAQEBAAAAAAAAAAAAAAAAAAEgIf/aAAgBAgEBPxAVMY//xAAgEAADAAAFBQAAAAAAAAAAAAAAATERIUFx8VFhkbHR/9oACAEBAAE/EDs57hays5l9HtIR4lN+Ba7iWVfnYayrnUS2n//Z'); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"execution of one thread block\"\n        title=\"\"\n        src=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/1697e/block.jpg\"\n        srcset=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/a2cfd/block.jpg 148w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/3348f/block.jpg 295w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/1697e/block.jpg 590w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/f4f50/block.jpg 677w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </span>\n  </a></p>\n<h4>the execution of the for-loop</h4>\n<p>Use <code class=\"language-text\">thread(0,0)</code> in <code class=\"language-text\">block(0,0)</code> as an example.</p>\n<ul>\n<li>\n<p>During the 0th iteration (k=0):</p>\n<ul>\n<li><code class=\"language-text\">Row * Width + k = 0*4+0 = 0</code></li>\n<li><code class=\"language-text\">k * Width + Col= 0*4+0 = 0</code></li>\n<li>Therefore, we are accessing <code class=\"language-text\">M[0]</code> and <code class=\"language-text\">N[0]</code>, which are the 1D equivalent of <code class=\"language-text\">M(0,0)</code> and <code class=\"language-text\">N(0,0)</code></li>\n</ul>\n</li>\n<li>\n<p>During the 1st iteration (k=1):</p>\n<ul>\n<li><code class=\"language-text\">Row * Width + k = 0*4+1 = 1</code></li>\n<li><code class=\"language-text\">k * Width + Col = 1*4+0 = 4</code></li>\n<li>We are accessing <code class=\"language-text\">M[1]</code> and <code class=\"language-text\">N[4]</code>, which are the 1D equivalent of <code class=\"language-text\">M(0,1)</code> and <code class=\"language-text\">N(1,0)</code></li>\n</ul>\n</li>\n</ul>\n<h2>Tiled Kernel</h2>\n<p>To see how to use tiling (corner turning) technique to overcome the fact that row-wise access of matrix M cannot be coalesced, see <em>Corner Turning</em> section in <a href=\"./cuda5-coalesce\">The CUDA Parallel Programming Model - 5.Memory Coalescing</a>.</p>",
        "fields": { "readingTime": { "text": "3 min read" } },
        "frontmatter": {
          "title": "CUDA Programming - 1. Matrix Multiplication",
          "date": "December 07, 2019"
        }
      }
    },
    "pageContext": {
      "isCreatedByStatefulCreatePages": false,
      "slug": "/cudaProg1-matrixmult/",
      "previous": {
        "fields": { "slug": "/cuda6-memoryparallel/" },
        "frontmatter": {
          "title": "The CUDA Parallel Programming Model - 6. Memory Parallelism"
        }
      },
      "next": {
        "fields": { "slug": "/cudaProg2-Variables/" },
        "frontmatter": {
          "title": "CUDA Programming - 2. CUDA Variable Type Qualifiers"
        }
      }
    }
  }
}
