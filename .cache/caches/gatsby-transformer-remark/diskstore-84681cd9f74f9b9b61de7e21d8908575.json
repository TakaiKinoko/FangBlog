{
  "expireTime": 9007200830740022000,
  "key": "transformer-remark-markdown-html-ast-3ce66e25819aec4e26c6fa298505ecf1-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": {
    "type": "root",
    "children": [
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "There’s an intrinsic tradeoff in the use of device memories in CUDA: the ",
            "position": {
              "start": { "line": 2, "column": 1, "offset": 1 },
              "end": { "line": 2, "column": 74, "offset": 74 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "global memory",
                "position": {
                  "start": { "line": 2, "column": 76, "offset": 76 },
                  "end": { "line": 2, "column": 89, "offset": 89 }
                }
              }
            ],
            "position": {
              "start": { "line": 2, "column": 74, "offset": 74 },
              "end": { "line": 2, "column": 91, "offset": 91 }
            }
          },
          {
            "type": "text",
            "value": " is large but slow, whereas the ",
            "position": {
              "start": { "line": 2, "column": 91, "offset": 91 },
              "end": { "line": 2, "column": 123, "offset": 123 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "shared memory",
                "position": {
                  "start": { "line": 2, "column": 125, "offset": 125 },
                  "end": { "line": 2, "column": 138, "offset": 138 }
                }
              }
            ],
            "position": {
              "start": { "line": 2, "column": 123, "offset": 123 },
              "end": { "line": 2, "column": 140, "offset": 140 }
            }
          },
          {
            "type": "text",
            "value": " is small but fast.",
            "position": {
              "start": { "line": 2, "column": 140, "offset": 140 },
              "end": { "line": 2, "column": 159, "offset": 159 }
            }
          }
        ],
        "position": {
          "start": { "line": 2, "column": 1, "offset": 1 },
          "end": { "line": 2, "column": 159, "offset": 159 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "(To recap on the memory hierarchy: ",
            "position": {
              "start": { "line": 4, "column": 1, "offset": 161 },
              "end": { "line": 4, "column": 36, "offset": 196 }
            }
          },
          {
            "type": "element",
            "tagName": "a",
            "properties": { "href": "/cuda1" },
            "children": [
              {
                "type": "text",
                "value": "The CUDA Parallel Programming Model - 1. Concepts",
                "position": {
                  "start": { "line": 4, "column": 37, "offset": 197 },
                  "end": { "line": 4, "column": 86, "offset": 246 }
                }
              }
            ],
            "position": {
              "start": { "line": 4, "column": 36, "offset": 196 },
              "end": { "line": 4, "column": 95, "offset": 255 }
            }
          },
          {
            "type": "text",
            "value": ", on how to specify memories for variables: ",
            "position": {
              "start": { "line": 4, "column": 95, "offset": 255 },
              "end": { "line": 4, "column": 139, "offset": 299 }
            }
          },
          {
            "type": "element",
            "tagName": "a",
            "properties": { "href": "/cudaProg2-Variables" },
            "children": [
              {
                "type": "text",
                "value": "CUDA Programming - 2. CUDA Variable Type Qualifiers",
                "position": {
                  "start": { "line": 4, "column": 140, "offset": 300 },
                  "end": { "line": 4, "column": 191, "offset": 351 }
                }
              }
            ],
            "position": {
              "start": { "line": 4, "column": 139, "offset": 299 },
              "end": { "line": 4, "column": 214, "offset": 374 }
            }
          },
          {
            "type": "text",
            "value": ".)",
            "position": {
              "start": { "line": 4, "column": 214, "offset": 374 },
              "end": { "line": 4, "column": 216, "offset": 376 }
            }
          }
        ],
        "position": {
          "start": { "line": 4, "column": 1, "offset": 161 },
          "end": { "line": 4, "column": 216, "offset": 376 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "A common strategy to reduce memory traffic is to partition the ",
            "position": {
              "start": { "line": 6, "column": 1, "offset": 378 },
              "end": { "line": 6, "column": 64, "offset": 441 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "data",
                "position": {
                  "start": { "line": 6, "column": 66, "offset": 443 },
                  "end": { "line": 6, "column": 70, "offset": 447 }
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 64, "offset": 441 },
              "end": { "line": 6, "column": 72, "offset": 449 }
            }
          },
          {
            "type": "text",
            "value": " into subsets called ",
            "position": {
              "start": { "line": 6, "column": 72, "offset": 449 },
              "end": { "line": 6, "column": 93, "offset": 470 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "tiles",
                "position": {
                  "start": { "line": 6, "column": 95, "offset": 472 },
                  "end": { "line": 6, "column": 100, "offset": 477 }
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 93, "offset": 470 },
              "end": { "line": 6, "column": 102, "offset": 479 }
            }
          },
          {
            "type": "text",
            "value": " so that ",
            "position": {
              "start": { "line": 6, "column": 102, "offset": 479 },
              "end": { "line": 6, "column": 111, "offset": 488 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "each tile fits into the shared memory",
                "position": {
                  "start": { "line": 6, "column": 113, "offset": 490 },
                  "end": { "line": 6, "column": 150, "offset": 527 }
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 111, "offset": 488 },
              "end": { "line": 6, "column": 152, "offset": 529 }
            }
          },
          {
            "type": "text",
            "value": ". An important criterion is that kernel computation on these tiles can be performed independently of each other. Note that ",
            "position": {
              "start": { "line": 6, "column": 152, "offset": 529 },
              "end": { "line": 6, "column": 275, "offset": 652 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "not",
                "position": {
                  "start": { "line": 6, "column": 277, "offset": 654 },
                  "end": { "line": 6, "column": 280, "offset": 657 }
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 275, "offset": 652 },
              "end": { "line": 6, "column": 282, "offset": 659 }
            }
          },
          {
            "type": "text",
            "value": " all data structures can be partitioned into tiles given an arbitrary kernel function.",
            "position": {
              "start": { "line": 6, "column": 282, "offset": 659 },
              "end": { "line": 6, "column": 368, "offset": 745 }
            }
          }
        ],
        "position": {
          "start": { "line": 6, "column": 1, "offset": 378 },
          "end": { "line": 6, "column": 368, "offset": 745 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "The term “tile” draws on the analogy that a large wall (i.e., the global memory data) can be covered by tiles (i.e., subsets that each can fit into the shared memory).",
            "position": {
              "start": { "line": 8, "column": 1, "offset": 747 },
              "end": { "line": 8, "column": 168, "offset": 914 }
            }
          }
        ],
        "position": {
          "start": { "line": 8, "column": 1, "offset": 747 },
          "end": { "line": 8, "column": 168, "offset": 914 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "To illustrate the concept of tiling, we use the example from ",
            "position": {
              "start": { "line": 10, "column": 1, "offset": 916 },
              "end": { "line": 10, "column": 62, "offset": 977 }
            }
          },
          {
            "type": "element",
            "tagName": "a",
            "properties": { "href": "/cudaProg1-matrixmult" },
            "children": [
              {
                "type": "text",
                "value": "CUDA Programming - 1. Matrix Multiplication",
                "position": {
                  "start": { "line": 10, "column": 63, "offset": 978 },
                  "end": { "line": 10, "column": 106, "offset": 1021 }
                }
              }
            ],
            "position": {
              "start": { "line": 10, "column": 62, "offset": 977 },
              "end": { "line": 10, "column": 130, "offset": 1045 }
            }
          },
          {
            "type": "text",
            "value": ", assumes that we use four 2×2 blocks to compute the P matrix. The picture below highlights the computation performed by the four threads of block(0,0):",
            "position": {
              "start": { "line": 10, "column": 130, "offset": 1045 },
              "end": { "line": 10, "column": 282, "offset": 1197 }
            }
          }
        ],
        "position": {
          "start": { "line": 10, "column": 1, "offset": 916 },
          "end": { "line": 10, "column": 282, "offset": 1197 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "raw",
            "value": "<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/e1ec8/block.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.9320531757755%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAEFAgMG/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAHoKTfjm2g1IkJB/8QAGxAAAQQDAAAAAAAAAAAAAAAAAAECAwQUIDL/2gAIAQEAAQUCL3ZlKTP1/8QAFREBAQAAAAAAAAAAAAAAAAAAASD/2gAIAQMBAT8BRj//xAAWEQADAAAAAAAAAAAAAAAAAAABAiD/2gAIAQIBAT8BDR//xAAdEAABAgcAAAAAAAAAAAAAAAABAAIQERIgMkGh/9oACAEBAAY/Ak2GPE00AzGxb//EABsQAAICAwEAAAAAAAAAAAAAAAABEbEQIDFh/9oACAEBAAE/IStePQJ26EPrGiP/2gAMAwEAAgADAAAAEAAIAP/EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAEDAQE/EBR//8QAFREBAQAAAAAAAAAAAAAAAAAAASD/2gAIAQIBAT8QFSP/xAAgEAADAAAFBQAAAAAAAAAAAAAAATERIUFx8VFhkbHR/9oACAEBAAE/EDs57hays5l9HMJR4lN+Ba7iWVfnYayrnUS2n//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"block\"\n        title=\"block\"\n        src=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/88218/block.jpg\"\n        srcset=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/7237a/block.jpg 148w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/0cfdf/block.jpg 295w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/88218/block.jpg 590w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/e1ec8/block.jpg 677w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>",
            "position": {
              "start": { "line": 12, "column": 1, "offset": 1199 },
              "end": { "line": 12, "column": 17, "offset": 1215 }
            }
          }
        ],
        "position": {
          "start": { "line": 12, "column": 1, "offset": 1199 },
          "end": { "line": 12, "column": 17, "offset": 1215 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "Another picture (below) is used to show the global memory accesses performed by block(0, 0). Among the four threads highlighted, a significant ",
            "position": {
              "start": { "line": 14, "column": 1, "offset": 1217 },
              "end": { "line": 14, "column": 144, "offset": 1360 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "overlap",
                "position": {
                  "start": { "line": 14, "column": 146, "offset": 1362 },
                  "end": { "line": 14, "column": 153, "offset": 1369 }
                }
              }
            ],
            "position": {
              "start": { "line": 14, "column": 144, "offset": 1360 },
              "end": { "line": 14, "column": 155, "offset": 1371 }
            }
          },
          {
            "type": "text",
            "value": " occurs in the M and N elements they access.",
            "position": {
              "start": { "line": 14, "column": 155, "offset": 1371 },
              "end": { "line": 14, "column": 199, "offset": 1415 }
            }
          }
        ],
        "position": {
          "start": { "line": 14, "column": 1, "offset": 1217 },
          "end": { "line": 14, "column": 199, "offset": 1415 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "raw",
            "value": "<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/383c503ca2b90562629741e19a053781/dfb83/block00.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 32.97985153764581%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAdiAsD//xAAXEAADAQAAAAAAAAAAAAAAAAAAARAh/9oACAEBAAEFAtFP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAGBAAAwEBAAAAAAAAAAAAAAAAAAEhYXH/2gAIAQEAAT8h6hDZdP/aAAwDAQACAAMAAAAQc8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAEBAAIDAAAAAAAAAAAAAAABEQAhMUGR/9oACAEBAAE/EKo3o0vOBioM7wUbfTn/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"block00\"\n        title=\"block00\"\n        src=\"/static/383c503ca2b90562629741e19a053781/88218/block00.jpg\"\n        srcset=\"/static/383c503ca2b90562629741e19a053781/7237a/block00.jpg 148w,\n/static/383c503ca2b90562629741e19a053781/0cfdf/block00.jpg 295w,\n/static/383c503ca2b90562629741e19a053781/88218/block00.jpg 590w,\n/static/383c503ca2b90562629741e19a053781/77d57/block00.jpg 885w,\n/static/383c503ca2b90562629741e19a053781/dfb83/block00.jpg 943w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>",
            "position": {
              "start": { "line": 16, "column": 1, "offset": 1417 },
              "end": { "line": 16, "column": 19, "offset": 1435 }
            }
          }
        ],
        "position": {
          "start": { "line": 16, "column": 1, "offset": 1417 },
          "end": { "line": 16, "column": 19, "offset": 1435 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "If thread(0, 0) and thread(0, 1) can be made to collaborate so that these M elements are only loaded from the global memory once, the total number of accesses to the global memory can be reduced by half. ",
            "position": {
              "start": { "line": 18, "column": 1, "offset": 1437 },
              "end": { "line": 18, "column": 205, "offset": 1641 }
            }
          }
        ],
        "position": {
          "start": { "line": 18, "column": 1, "offset": 1437 },
          "end": { "line": 18, "column": 205, "offset": 1641 }
        }
      }
    ],
    "position": {
      "start": { "line": 1, "column": 1, "offset": 0 },
      "end": { "line": 19, "column": 1, "offset": 1642 }
    }
  }
}
