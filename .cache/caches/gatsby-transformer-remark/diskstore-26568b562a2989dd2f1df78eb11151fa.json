{
  "expireTime": 9007200830735197000,
  "key": "transformer-remark-markdown-html-801dd76926238fdc0df7d426a1cada56-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": "<p>This is the second post in a series about what I learnt in my GPU class at NYU this past fall. This will be mostly about warps, why using warps from a SIMD hardware standpoint, and how warps can be a dangerous thing to deal with.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li>\n<p>More About Threads</p>\n<ol>\n<li>Kernel threads hierarchy</li>\n<li>Synchronization of threads?</li>\n</ol>\n</li>\n<li>\n<p>Warp</p>\n<ol>\n<li>practical reasons</li>\n<li><strong>SIMD hardware</strong></li>\n<li>practical reasons to share control unit amongst processing units</li>\n</ol>\n</li>\n<li>\n<p>How Are Blocks Partitioned?</p>\n<ol>\n<li>1D block</li>\n<li>2D block</li>\n<li>3D block</li>\n</ol>\n</li>\n<li>\n<p>Warp Execution</p>\n<ol>\n<li>when is it good?</li>\n<li>when is it bad? <strong>thread divergence</strong></li>\n<li>multipass aproach &#x26; divergence</li>\n<li>if-else example</li>\n<li>for-loop example</li>\n<li>other scenarios</li>\n</ol>\n</li>\n</ol>\n<h2>More About Threads</h2>\n<h3>Kernel threads hierarchy</h3>\n<p>Recall that launching a CUDA kernel will generate a grid of threads organized as a <strong>two-level</strong> hierarchy.</p>\n<ol>\n<li>top level: a 1/2/3-dimensional array of blocks.</li>\n<li>bottom level: each block consists of a 1/2/3-dimensional array of threads.</li>\n</ol>\n<h3>Thread Assignment</h3>\n<ul>\n<li>Threads are assigned to execution <strong>resources</strong> on a <strong>block-by-block</strong> basis.</li>\n<li>But the unit of thread scheduling is warp.</li>\n</ul>\n<h3>Synchronization of threads?</h3>\n<p>Conceptually, threads in a block can execute in any order, just like blocks.</p>\n<p>When an algorithm needs to execute in <em>phases</em>, <strong>barrier synchronizations</strong> should be used to ensure that all threads have completed a common phase before they start the next one.</p>\n<p>But the correctness of executing a kernel should not depend on the synchrony amongst threads.</p>\n<h2>Warp</h2>\n<p>Due to hardware cost considerations, CUDA devices currently bundle multiple threads for execution, which leads to performance limitations.</p>\n<ul>\n<li>üßê<strong>Each thread block is partitioned into warps</strong> when the block is assigned to an SM.</li>\n<li>The warp is a unit of thread scheduling in SMs.</li>\n<li>Each warp consists of 32 threads of consecutive thredIdx values.</li>\n<li>The execution of warps is implemented by an SIMD hardware.</li>\n<li>Warps can be executed by the SMs in any order. No way to tell who‚Äôs going to finish first.</li>\n</ul>\n<h3>warp as an execution unit</h3>\n<p>An SM is designed to execute all threads in a warp following the SIMD model ‚Äî at any instant in time, one instruction is fetched and executed for all threads in a warp. In the picture below, there‚Äôs a single instruction fetch/dispatch shared among execution units(SPs) in th eSM. These threads will apply the same instruction to different portions of the data. Consequently, all threads in a warp will always have the <strong>same execution timing</strong>.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7d0d5d70a704e8cdf6e5ff7a7a40aeb5/76aaf/warp.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 85.04098360655738%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAABYlAAAWJQFJUiTwAAACbklEQVQ4y5VTS0uyYRDtp9kf0EWQIClYuBKJXLkxKlcRoQXeUAjBTSgEIbRIyGgZFYqXvGSm5rUiW3Wxzvedgef9SiL6BobneY/znJk5M07hr72/v+P19RXPz894eXnB29sbYTn5TZzOuJ/wj48PTPHS7XaRzWbRbrdxdXWFRqMhj+r1OvL5PG5ublAul3F7eysPeS8WixJXrVbR6XSgTAgJNJtNVCoVCSoUCjg/P5cExOgkvbi4kCSMvby8FLzVauHs7Ay1Wu0rIf34+BgbGxtYW1vD0dGRPGQliUQCKysrCIVCUhFJiSeTSXg8Hvj9fkmgETKLIrTZbJifn8fJyYm0z8yRSASzs7NYXl6WttnB9fU1otEojEYjVldXJblGSIHZ3v7+vlS3vr6O09NTPD09SZs7OztCRmI+fHx8FM1jsRhcLpcQUxIh5GRo4/EY/X4fDw8PuL+/l6qZiN+8c3DsgjGM7fV6Ui1jh8MhRqPRvwoVqTJWwOqoFyeqTjploPN3JvtssjaKjKfaJwam02kZQiAQEAk2NzdlYMFgEOFwGKlUCoPBQHuneKYmM9DYBh9sbW1he3sbPp9P7iT1er3iu7u72l5+7vBbQmpC8UulkqwDJ802uSq5XE5ap6bU80dC1TKX2+12w+l04vDwUKtaYdwAlXhS/28Jubgmkwk6nQ7xeFwwrsXMzAymp6dxcHAgGDX8VYVc2qWlJVitVuzt7QlGvRwOh2CZTEYj/HWFCwsL0Ov1Ij6Ni2+xWGAwGGQD/ptwcXERc3NzXyq02+0wm81ahRzKj4TqRy723d2d9q/hnSe/FcaB0Cc1/AOSB7cMs9u41gAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"warp\"\n        title=\"warp\"\n        src=\"/static/7d0d5d70a704e8cdf6e5ff7a7a40aeb5/799d3/warp.png\"\n        srcset=\"/static/7d0d5d70a704e8cdf6e5ff7a7a40aeb5/00d96/warp.png 148w,\n/static/7d0d5d70a704e8cdf6e5ff7a7a40aeb5/0b23c/warp.png 295w,\n/static/7d0d5d70a704e8cdf6e5ff7a7a40aeb5/799d3/warp.png 590w,\n/static/7d0d5d70a704e8cdf6e5ff7a7a40aeb5/2a3d6/warp.png 885w,\n/static/7d0d5d70a704e8cdf6e5ff7a7a40aeb5/76aaf/warp.png 976w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>The picture also shows a number of SPs. In general: </p>\n<ul>\n<li>there are fewer SPs than the threads assigned to each SM</li>\n<li>each SM has only enough hardware to execute instructions from a small subset of all threads assigned to the SM at any point in time.</li>\n</ul>\n<p>In early GPU designs, each SM can execute only one instruction for a single warp at any given instant.</p>\n<p>In recent designs, each SM can execute instructions for a small numver of warps at any point in time.</p>\n<p>In either case, the hardware can execute instructions for a small subset of all warps in the SM.</p>\n<h4>practical reasons</h4>\n<p>This implementation (doesn‚Äôt just exist to annoy programmers) helps:</p>\n<ol>\n<li>reducing hardware manufacturing cost</li>\n<li>lower runtime operation electricity cost</li>\n<li>enable coalescing of memory accesses (which will be the topic of some later post)</li>\n</ol>\n<h4>SIMD hardware</h4>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/dd7852cc44b3614e54dbf83a6304f750/0aa3a/processor.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.51155115511551%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAABYlAAAWJQFJUiTwAAACDElEQVQ4y21T2ZLaQAzk/z9nK8kmu7BcAZbl8jFg4wNMFbzYYK4qjqeOWsSbEPIgjy1pWq2WXLper9jvD2rb7Q55vlXbbHL9PhyO/43tdnuN8SzscrmgROd8vkAQRHAcg+k0hO8HCMMYtuWiXm+i3X6H6441hzGeo5GNXm8Ay3IwHFqaz6IlVve8qYINBiOMx55e5oVatY5vX5/xVqnpZfpt21X7+Oij0+nqnX5/qEXyXABJ37aNAhVgPBuNpiQOEIWRsA7gTTwp7GMiZxzP9DRmomRYII7nKkeJDzrJgNTJjNUtOanv6XRCmqZYrVZYJAlWy6XotUOSLLR9ykUCD4AvL2U8PX1BufwmujWklQG2eY4szQRoIYPZK7BxDcIglBZvWhOITB8Au92eMlOWYo7jIssyHI9HZXcQwL0wC6T9pbAMVYoQs1nyCDgRQM+fwgj1MJohkIndtJyoBKORJQN4F60c9RkzFg19NQLdtbxeb7QC6ZMpjYn0VWXKtEqlitbPjsaM8TTX90O4v4fC/EiIKGCWbT7FJX0a2242W5qs/nmil1qtjq4Xc4rd/QQsGHJtSPnWwm11uAY90ZO6DmXPWKAjy90WwGKtmM93XzS9Y8gHK1HgwhgkKBf69bWCWq2B788/tH0y+TuXfwgLkLUCns9nnWaa3luWrfWfpcbr9Z/3f/NojHM3ifULGb2fyrgSzdgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"processor\"\n        title=\"processor\"\n        src=\"/static/dd7852cc44b3614e54dbf83a6304f750/799d3/processor.png\"\n        srcset=\"/static/dd7852cc44b3614e54dbf83a6304f750/00d96/processor.png 148w,\n/static/dd7852cc44b3614e54dbf83a6304f750/0b23c/processor.png 295w,\n/static/dd7852cc44b3614e54dbf83a6304f750/799d3/processor.png 590w,\n/static/dd7852cc44b3614e54dbf83a6304f750/2a3d6/processor.png 885w,\n/static/dd7852cc44b3614e54dbf83a6304f750/ae92f/processor.png 1180w,\n/static/dd7852cc44b3614e54dbf83a6304f750/0aa3a/processor.png 1212w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">processor</figcaption>\n  </figure></p>\n<ul>\n<li>The processor has only <em>one</em> <strong>control unit</strong> that fetches and decodes instruction.</li>\n<li>The same control signal goes to <em>multiple</em> <strong>processing units</strong>, each of which executes one of the threads in a warp.</li>\n<li>Since all <strong>processing units</strong> are controlled by the same instruction, their execution differences are due to the different operands in the <strong>register files</strong>.</li>\n</ul>\n<p>This is called Single-Instruction-Multiple-Data in processor design.</p>\n<h5>practical reasons to share control unit amongst processing units</h5>\n<ul>\n<li>\n<p>Control units are quite complex:</p>\n<ul>\n<li>sophisticated logic for fetching instructions</li>\n<li>access ports to the instruction memory</li>\n<li>on-chip instruction caches to reduce the latency of instruction fetch.</li>\n</ul>\n</li>\n<li>Having multiple processing units share a control unit can result in significant reduction in hardware manufacturing cost and power consumption.</li>\n</ul>\n<h2>How Are Blocks Partitioned?</h2>\n<p>Based on thread indices. Thread IDs within a warp are consecutive and increasing.</p>\n<ol>\n<li>\n<p>Example with <em>1D thread block</em>:</p>\n<ul>\n<li>only threadIdx.x is used, threadIdx.x values within a warp are consecutive and increasing.</li>\n<li>for a warp size of 32:</li>\n<li>warp 0: thread 0 ~ thread 31</li>\n<li>warp 1: thread 32 ~ thread 63</li>\n<li>warp n: thread 32 √ó n ~ thread 32(n + 1) - 1</li>\n<li>for a block of which the size is not a multiple of 32:</li>\n<li>the last warp will be <strong>padded with extra threads</strong> to fill up the 32 threads.</li>\n</ul>\n</li>\n<li>\n<p><em>2D thread block</em>:</p>\n<ul>\n<li>the dimensions will be <em>projected into a linear order</em> <strong>before</strong> partitioning into warps</li>\n</ul>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1b336777349cc0288199bf1472bf368c/ec071/2D.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 49.479166666666664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB+UlEQVQoz32Sy2tTQRSHxyLiQhe6kyLYxLQWi48/wY1QEP+Agi7cdFOJq+qiK6la3ChUDD7y2CiIYCiCj4WF4KO2AUVFTaBJm9uY9BHyvHndeyefc29aTG31wMecYc785jxGsG6tVsthw7fNtEroxivFS8VrxXMa1hcV4ETReXfDxPZi0vHXshHS0R0szQmWol1oM4Lc/BCyZcdZSCm3Cm6XmWUYVBS59+9Y3reHzN7dZNSa7RKsXjjPT01jPh4nkUjQbDY33RVbyjRNCvmC489GvnFy1yUGxEVO7PTiFsOMDgVZWcuQTC6gKeFarbZZsHNjqKxKpRLWeinTnz4gTrsUBxFnDiFO7efsxAh/W2dSKkPp9KzRqCqxvOqPoU4s6uUq2mqCqy9GufJ0hMtTXrzhYZ58fuTMo2mYGKahBmdiyjaWtNoZNhpQrf550X5C53/W+ueJ0PUY2eVbSjBEpRxQwwiSm/ZRnLyHHgpS9j+gEvTz+PYz7j6cIRD4iM/3lsk7b7gfCRCMBgjNhfDP+gl/DSOKxSkWF7tJpw+TSrpZyLtIj/WycqCPtMdF1uOhcPwY54546XbfxOMeV1yn7+g1PGMD9N5w0z/RT894D4O+QbtkiaX6IGUHqjf21zHqdX6pScZ+fCcWi5NKaVQquhqe2UbFdWL38zfzOrIVqOrk/wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"linearized2D\"\n        title=\"linearized2D\"\n        src=\"/static/1b336777349cc0288199bf1472bf368c/799d3/2D.png\"\n        srcset=\"/static/1b336777349cc0288199bf1472bf368c/00d96/2D.png 148w,\n/static/1b336777349cc0288199bf1472bf368c/0b23c/2D.png 295w,\n/static/1b336777349cc0288199bf1472bf368c/799d3/2D.png 590w,\n/static/1b336777349cc0288199bf1472bf368c/2a3d6/2D.png 885w,\n/static/1b336777349cc0288199bf1472bf368c/ae92f/2D.png 1180w,\n/static/1b336777349cc0288199bf1472bf368c/ec071/2D.png 1536w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">linearized2D</figcaption>\n  </figure></p>\n<ul>\n<li>determine the linear order: place the rows with larger y and z coordinates after those with lower ones.</li>\n</ul>\n</li>\n<li>\n<p><em>3D thread block</em>:</p>\n<ul>\n<li>first place all threads of which the threadIdx.z value is 0 into the linear order. Among these threads, they are treated as a 2D block as shown in above picture</li>\n<li>example: a 3D thread block of dimensions 2 √ó 8 √ó 4</li>\n<li>total 64 threads</li>\n<li>warp 0: T(0,0,0) ~ T(0,7,3)</li>\n<li>warp 1: T(1,0,0) ~ T(1,7,3)</li>\n</ul>\n</li>\n</ol>\n<h2>Warp Execution</h2>\n<p>All threads of a warp are executed by the SIMD hardware as a bundle, where the same instruction is run for all threads.</p>\n<p>Warp is the unit of <strong>thread scheduling</strong> in SMs.</p>\n<h3>when is it good?</h3>\n<p>When all threads within a warp follow the same control flow.</p>\n<p>For example, for an if-else construct, the execution works well when either all threads execute the if part or all execute the else part.</p>\n<h3>when is it bad?</h3>\n<p>When threads within a warp take different control flow paths, the SIMD hardware will take <em>multiple passes</em> through these divergent paths. During each pass, the threads that follow the other path are not allowed to take effect.</p>\n<p>These passes are <em>sequential</em> to each other, thus they will add to the execution time.</p>\n<h4>multipass aproach &#x26; divergence</h4>\n<ul>\n<li>The <strong>multipass approach</strong> to <strong>divergent warp execution</strong> extends the SIMD hardware‚Äôs ability to implement the full semantics of CUDA threads. While the hardware executes the same instruction for all threads in a warp, it selectively lets the threads take effect in each pass only, allowing every thread to take its own control flow path. This preserves the independence of threads while taking advantage of the reduced cost of SIMD hardware.</li>\n<li>When threads <em>in the same warp</em> follow different paths of control flow, we say that these threads <strong>diverge</strong> in their execution.</li>\n</ul>\n<h4>if-else example</h4>\n<p>In the if-else example, divergence arises if some threads in a warp take the then path and some the else path. The cost of divergence is the <em>extra pass</em> the hardware needs to take to allow the threads in a warp to make their own decisions.</p>\n<h4>for-loop example</h4>\n<p>If threads in a warp execute a for loop that can iterate <strong>six, seven, or eight</strong> times for different threads:</p>\n<ul>\n<li>All threads will finish the first six iterations together.</li>\n<li>Two passes will be used to execute the seventh iteration, one for those that take the iteration and one for those that do not.</li>\n<li>Two passes will be used to execute the eighth iteration, one for those that take the iteration and one for those that do not.</li>\n</ul>\n<h4>other scenarios</h4>\n<p>In terms of source statements, a control construct can result in thread divergence when its decision condition is based on threadIdx values.</p>\n<p>For example, the statement <code class=\"language-text\">if (threadIdx.x. &gt; 2) {}</code> causes the threads to follow two divergent control flow paths. Threads 0, 1, and 2 follow a different path than threads 3, 4, 5, etc.</p>\n<p>Similarly, a loop can cause thread divergence if its loop condition is based on thread index values.</p>"
}
