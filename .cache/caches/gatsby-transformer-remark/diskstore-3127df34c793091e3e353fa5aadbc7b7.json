{
  "expireTime": 9007200830740281000,
  "key": "transformer-remark-markdown-html-79909c0e6162f95f30dc88cd8bc35455-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": "<p>There’s an intrinsic tradeoff in the use of device memories in CUDA: the <strong>global memory</strong> is large but slow, whereas the <strong>shared memory</strong> is small but fast.</p>\n<p>(To recap on the memory hierarchy: <a href=\"/cuda1\">The CUDA Parallel Programming Model - 1. Concepts</a>, on how to specify memories for variables: <a href=\"/cudaProg2-Variables\">CUDA Programming - 2. CUDA Variable Type Qualifiers</a>.)</p>\n<p>A common strategy to reduce memory traffic is to partition the <strong>data</strong> into subsets called <strong>tiles</strong> so that <strong>each tile fits into the shared memory</strong>. An important criterion is that kernel computation on these tiles can be performed independently of each other. Note that <strong>not</strong> all data structures can be partitioned into tiles given an arbitrary kernel function.</p>\n<p>The term “tile” draws on the analogy that a large wall (i.e., the global memory data) can be covered by tiles (i.e., subsets that each can fit into the shared memory).</p>\n<p>To illustrate the concept of tiling, we use the example from <a href=\"/cudaProg1-matrixmult\">CUDA Programming - 1. Matrix Multiplication</a>, assumes that we use four 2×2 blocks to compute the P matrix. The picture below highlights the computation performed by the four threads of block(0,0):</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/e1ec8/block.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 97.9320531757755%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAIDAAAAAAAAAAAAAAAAAAEFAgMG/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAEC/9oADAMBAAIQAxAAAAHoKTfjm2g1IkJB/8QAGxAAAQQDAAAAAAAAAAAAAAAAAAECAwQUIDL/2gAIAQEAAQUCL3ZlKTP1/8QAFREBAQAAAAAAAAAAAAAAAAAAASD/2gAIAQMBAT8BRj//xAAWEQADAAAAAAAAAAAAAAAAAAABAiD/2gAIAQIBAT8BDR//xAAdEAABAgcAAAAAAAAAAAAAAAABAAIQERIgMkGh/9oACAEBAAY/Ak2GPE00AzGxb//EABsQAAICAwEAAAAAAAAAAAAAAAABEbEQIDFh/9oACAEBAAE/IStePQJ26EPrGiP/2gAMAwEAAgADAAAAEAAIAP/EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAEDAQE/EBR//8QAFREBAQAAAAAAAAAAAAAAAAAAASD/2gAIAQIBAT8QFSP/xAAgEAADAAAFBQAAAAAAAAAAAAAAATERIUFx8VFhkbHR/9oACAEBAAE/EDs57hays5l9HMJR4lN+Ba7iWVfnYayrnUS2n//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"block\"\n        title=\"block\"\n        src=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/88218/block.jpg\"\n        srcset=\"/static/8a6ac4a5ad16d10fb7057c2042b31ad6/7237a/block.jpg 148w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/0cfdf/block.jpg 295w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/88218/block.jpg 590w,\n/static/8a6ac4a5ad16d10fb7057c2042b31ad6/e1ec8/block.jpg 677w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Another picture (below) is used to show the global memory accesses performed by block(0, 0). Among the four threads highlighted, a significant <strong>overlap</strong> occurs in the M and N elements they access.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/383c503ca2b90562629741e19a053781/dfb83/block00.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 32.97985153764581%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAdiAsD//xAAXEAADAQAAAAAAAAAAAAAAAAAAARAh/9oACAEBAAEFAtFP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAGBAAAwEBAAAAAAAAAAAAAAAAAAEhYXH/2gAIAQEAAT8h6hDZdP/aAAwDAQACAAMAAAAQc8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAEBAAIDAAAAAAAAAAAAAAABEQAhMUGR/9oACAEBAAE/EKo3o0vOBioM7wUbfTn/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"block00\"\n        title=\"block00\"\n        src=\"/static/383c503ca2b90562629741e19a053781/88218/block00.jpg\"\n        srcset=\"/static/383c503ca2b90562629741e19a053781/7237a/block00.jpg 148w,\n/static/383c503ca2b90562629741e19a053781/0cfdf/block00.jpg 295w,\n/static/383c503ca2b90562629741e19a053781/88218/block00.jpg 590w,\n/static/383c503ca2b90562629741e19a053781/77d57/block00.jpg 885w,\n/static/383c503ca2b90562629741e19a053781/dfb83/block00.jpg 943w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>If thread(0, 0) and thread(0, 1) can be made to collaborate so that these M elements are only loaded from the global memory once, the total number of accesses to the global memory can be reduced by half.</p>\n<p>(The potential reduction in global memory traffic in the matrix multiplication example is proportional to the dimension of the blocks used. With Width ×Width blocks, the potential reduction of global memory traffic would be Width. Thus, if we use 16 ×16 blocks, the global memory traffic can be potentially reduced to 1/16 through collaboration between threads)</p>\n<h2>Tiled Algorithms</h2>\n<p>Tiled algorithms are highly similar to carpooling arrangements. We can consider <strong>threads</strong> accessing data values as commuters and <strong>DRAM access</strong> requests as vehicles.</p>\n<p>When the rate of DRAM requests exceeds the provisioned access <strong>bandwidth</strong> of the DRAM system, traffic congestion arises and the arithmetic units become idle.</p>\n<p>If multiple threads access data from the same DRAM location, they can potentially form a “carpool” and <strong>combine their accesses into one DRAM request</strong>.</p>\n<p>However, this process requires a <strong>similar execution schedule</strong> for the threads so that their data accesses can be combined.</p>\n<p>This scenario is shown in the picture below, where the cells at the center represent DRAM locations. An arrow from a DRAM location pointing to a thread represents an access by the thread to that location at the time marked by the head of the arrow. The top portion shows two threads that access the same data elements with similar timing. The bottom half shows two threads that access their common data at varying times; i.e., the accesses by Thread 2 lag significantly behind their corresponding accesses by Thread 1. The reason the bottom is an undesirable arrangement is that data elements that are brought back from the DRAM need to be stored in the on-chip memory for an extended time, waiting to be consumed by Thread 2. A large number of data elements will need to be stored, resulting in an excessive on-chip memory requirement.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 590px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8e1a2a97d68a8fbbc53aada41de8761a/d55e0/tiled.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.68792198049512%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAAB60tSRFSP/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAECERASQf/aAAgBAQABBQKbp7PDO0f/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAbEAACAQUAAAAAAAAAAAAAAAAAIQEgMTKRof/aAAgBAQAGPwJPRbsGdH//xAAbEAEBAAIDAQAAAAAAAAAAAAABABFRMWGBsf/aAAgBAQABPyFwwfQ+3fsRBUOslyiYaL//2gAMAwEAAgADAAAAEMv/AP/EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEDAQE/EGf/xAAWEQEBAQAAAAAAAAAAAAAAAAABEFH/2gAIAQIBAT8QEyf/xAAdEAEAAgICAwAAAAAAAAAAAAABABEhQTFRYbHx/9oACAEBAAE/EASxM1U9p1Xxcii1LXjiEHjZAIEEvc+NP//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"tiled\"\n        title=\"tiled\"\n        src=\"/static/8e1a2a97d68a8fbbc53aada41de8761a/88218/tiled.jpg\"\n        srcset=\"/static/8e1a2a97d68a8fbbc53aada41de8761a/7237a/tiled.jpg 148w,\n/static/8e1a2a97d68a8fbbc53aada41de8761a/0cfdf/tiled.jpg 295w,\n/static/8e1a2a97d68a8fbbc53aada41de8761a/88218/tiled.jpg 590w,\n/static/8e1a2a97d68a8fbbc53aada41de8761a/77d57/tiled.jpg 885w,\n/static/8e1a2a97d68a8fbbc53aada41de8761a/5a917/tiled.jpg 1180w,\n/static/8e1a2a97d68a8fbbc53aada41de8761a/d55e0/tiled.jpg 1333w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>"
}
