{
  "expireTime": 9007200830436909000,
  "key": "transformer-remark-markdown-html-fc62e8870dabffd00b32d1235aa6e0c1-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": "<p>This is the second post in a series about what I learnt in my GPU class at NYU this past fall. This will be mostly about <strong>warps and SIMD hardward</strong>.</p>\n<h2>Kernel threads hierarchy</h2>\n<p>Recall that launching a CUDA kernel will generate a grid of threads organized as a <strong>two-level</strong> hierarchy. </p>\n<ol>\n<li>\n<p>top level: a 1/2/3-dimensional array of blocks.</p>\n</li>\n<li>\n<p>bottom level: each block consists of a 1/2/3-dimensional array of threads.</p>\n</li>\n</ol>\n<h2>Synchronize threads?</h2>\n<p>Conceptually, threads in a block can execute in any order, just like blocks.</p>\n<p>When an algorithm needs to execute in <em>phases</em>, <strong>barrier synchronizations</strong> should be used to ensure that all threads have completed a common phase before they start the next one.</p>\n<h2>Warp</h2>\n<p>Due to considerations </p>"
}
