{
  "expireTime": 9007200830511313000,
  "key": "transformer-remark-markdown-html-7c62d9d46957b8510c58bee6db3ef43a-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": "<h2>CUDA Variable Type Qualifiers</h2>\n<p><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a4b97b85e330f441950542551e0ed2ca/d3ccf/qualifiers.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 40.03466204506066%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABWUlEQVQozz1R23aDMAzj/z9vW9t1jAAj3BNubSktpZrlne7BxyKRJTkEJm3xts9w+Cqxl/o4WJi0R9neUTSLFrH5GfAuvNA4hLHD/lggzuTsILNhpbzH44kgzTx2nxbH7wrHqMLuaJHYAbW/o/Gr1B1u2FDUs/AyRIlDkvUiaJHmowQp8B236KYntg0IhmFA3/da5/MZ3nvBHdqmUezaFqNw5vmCuq7RdR6cYee99w6Xy0XSPfB8SsIsE9cogjEx4jgGv40xijnIGqcJVVXpOUXzPP+fYbfWaqBNIgYEJNPtdDqhLEu0koqYd8Rd12EcRx0kds4pj/dFUajpuq5/CV+OFOUwO8mNrPx6CorRME1T5XCGPApzI2IaaUJechW6k8CeJImKUoREFnlcjwIs8mgahqHO00wF+SOYgP12u+H1k5ZlwfV61XOu/+rksuZ5Vg7NJnlj3nPlXxtcVw8Ff4nLAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"variable qualifiers\"\n        title=\"\"\n        src=\"/static/a4b97b85e330f441950542551e0ed2ca/d7711/qualifiers.png\"\n        srcset=\"/static/a4b97b85e330f441950542551e0ed2ca/a695b/qualifiers.png 148w,\n/static/a4b97b85e330f441950542551e0ed2ca/2f273/qualifiers.png 295w,\n/static/a4b97b85e330f441950542551e0ed2ca/d7711/qualifiers.png 590w,\n/static/a4b97b85e330f441950542551e0ed2ca/5e66f/qualifiers.png 885w,\n/static/a4b97b85e330f441950542551e0ed2ca/d3ccf/qualifiers.png 1154w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </span>\n  </a></p>\n<h4>lifetime == kernel?</h4>\n<ul>\n<li>\n<p>If the lifetime of a variable is within a kernel execution, it must be declared <strong>within the kernel function body</strong> and will be available for use only <strong>by the kernel code</strong></p>\n</li>\n<li>\n<p>If the kernel is invoked several times, the value of the variable is not maintained across these invocations. Each invocation must initialize the variable in order to use them</p>\n</li>\n</ul>\n<h4>lifetime == application?</h4>\n<ul>\n<li>\n<p>if the lifetime of a variable continues throughout the entire application, it must be declared <strong>outside of any function body</strong></p>\n</li>\n<li>\n<p>The contents of these variables are maintained throughout the execution of the application and available to all kernels</p>\n</li>\n</ul>\n<h4>scalar variables</h4>\n<ul>\n<li>\n<p>as shown in the picture above, all automatic scalar variables declared in <strong>kernel and device</strong> functions are placed into registers. </p>\n</li>\n<li>\n<p>The <strong>scopes</strong> of these automatic variables are <strong>within individual threads</strong>.</p>\n<ul>\n<li>\n<p>When a kernel function declares an automatic variable, a private copy of that variable is generated for every thread that executes the kernel function.</p>\n</li>\n<li>\n<p>When a thread terminates, all its automatic variables also cease to exist. Note that accessing these variables is extremely fast and parallel; however, one must be careful <em>not to exceed the limited capacity</em> of the register storage in hardware implementations.</p>\n</li>\n<li>\n<p>Using a large number of registers can negatively affect the number of active threads assigned to each SM.</p>\n</li>\n</ul>\n</li>\n</ul>\n<h4>array variables</h4>\n<p>Automatic array variables are not stored in registers.</p>\n<ul>\n<li>They are stored into the global memory</li>\n<li>may incur long access delays and potential access congestions</li>\n</ul>\n<p>Similar to automatic scalar variables, the scope of these arrays is limited to individual threads; i.e., a private version of each automatic array is created for and used by every thread.</p>\n<p>Once a thread terminates its execution, the contents of its automatic array variables also cease to exist. </p>\n<h4><code class=\"language-text\">__shared__</code></h4>\n<p>Declares a shared variable in CUDA. </p>\n<ul>\n<li>\n<p>An optional “<strong>device</strong>” in front of “<strong>shared</strong>” keyword may also be added in the declaration to achieve the <strong>same</strong> effect. </p>\n</li>\n<li>\n<p>Such declaration typically resides within a kernel function or a device function. </p>\n</li>\n<li>\n<p>Shared variables reside in the shared memory. </p>\n</li>\n<li>\n<p>The scope of a shared variable is within a thread block; i.e., all threads in a block see the same version of a shared variable. A private version of the shared variable is created for and used by each thread block during kernel execution. The lifetime of a shared variable is within the duration of the kernel. When a kernel terminates its execution, the contents of its shared variables cease to exist. As discussed earlier, shared variables are an efficient means for threads within a block to collaborate with one another. Accessing shared variables from the shared memory is extremely fast and highly parallel. CUDA programmers often use shared variables to hold the portion of global memory data that are heavily used in a kernel execution phase. </p>\n</li>\n</ul>"
}
