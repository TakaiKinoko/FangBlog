{
  "expireTime": 9007200830646894000,
  "key": "transformer-remark-markdown-ast-c6f2eb878a97b63f68313c8efe6856bb-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": {
    "type": "root",
    "children": [
      {
        "type": "paragraph",
        "children": [
          {
            "type": "text",
            "value": "In the last post, we saw how full concurrency can be achieved amongst streams. Here Iâ€™d like to talk about how CUDA operations from different streams may also be ",
            "position": {
              "start": { "line": 2, "column": 1, "offset": 1 },
              "end": { "line": 2, "column": 163, "offset": 163 },
              "indent": []
            }
          },
          {
            "type": "strong",
            "children": [
              {
                "type": "text",
                "value": "interleaved",
                "position": {
                  "start": { "line": 2, "column": 165, "offset": 165 },
                  "end": { "line": 2, "column": 176, "offset": 176 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 2, "column": 163, "offset": 163 },
              "end": { "line": 2, "column": 178, "offset": 178 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": ", which is another programming model often used to effect concurrency.",
            "position": {
              "start": { "line": 2, "column": 178, "offset": 178 },
              "end": { "line": 2, "column": 248, "offset": 248 },
              "indent": []
            }
          }
        ],
        "position": {
          "start": { "line": 2, "column": 1, "offset": 1 },
          "end": { "line": 2, "column": 248, "offset": 248 },
          "indent": []
        }
      },
      {
        "type": "heading",
        "depth": 2,
        "children": [
          {
            "type": "text",
            "value": "Review CUDA Asynchronous Commands",
            "position": {
              "start": { "line": 4, "column": 4, "offset": 253 },
              "end": { "line": 4, "column": 37, "offset": 286 },
              "indent": []
            }
          }
        ],
        "position": {
          "start": { "line": 4, "column": 1, "offset": 250 },
          "end": { "line": 4, "column": 38, "offset": 287 },
          "indent": []
        }
      },
      {
        "type": "paragraph",
        "children": [
          {
            "type": "text",
            "value": "(beyond multi-threaded parallelism)\nCUDA Kernel <<<>>>\ncudaMemcpyAsync (HostToDevice)\ncudaMemcpyAsync (DeviceToHost)\nOperations on the CPU",
            "position": {
              "start": { "line": 5, "column": 1, "offset": 288 },
              "end": { "line": 9, "column": 22, "offset": 426 },
              "indent": [1, 1, 1, 1]
            }
          }
        ],
        "position": {
          "start": { "line": 5, "column": 1, "offset": 288 },
          "end": { "line": 9, "column": 22, "offset": 426 },
          "indent": [1, 1, 1, 1]
        }
      }
    ],
    "position": {
      "start": { "line": 1, "column": 1, "offset": 0 },
      "end": { "line": 9, "column": 22, "offset": 426 }
    }
  }
}
