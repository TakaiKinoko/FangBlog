{
  "expireTime": 9007200830484345000,
  "key": "transformer-remark-markdown-html-19acd5f719115ae4a51186ad497b08d6-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": "<p>This post talks about a key factor to CUDA kernel performace: accessing data in the globle memory.</p>\n<p>CUDA applications tend to process a massive amount of data from the global memory within a short period of time. </p>\n<p><strong>Tiling</strong> techniques are engineered that utilize <strong>shared memories</strong> to reduce the total amount of data that must be acessed from the global memory (read about tiling techniques here <a href=\"/cuda6-tiling\">The CUDA Parallel Programming Model - 6.Tiling</a>). </p>\n<p>I this post we talk about <strong>memory coalescing</strong> techniques that can more effectively move data from the global memory into <strong>shared memories and registers</strong>. </p>\n<p>Memory coalescing techniques are often used <em>in conjunction with tiling techniques</em> to allow CUDA devices to reach their performance potential by more efficiently utilizing the global memory bandwidth.</p>\n<h2>Global Memory Bandwidth</h2>\n<p>The global memory of a CUDA device is implemented with DRAMs.</p>\n<h4>DRAM is slow</h4>\n<p>Data bits are stored in DRAM cells that are small capacitors, where the presence or absence of a <em>tiny amount of electrical charge</em> distinguishes between 0 and 1. </p>\n<p>Reading data from a DRAM cell requires the small capacitor to use its tiny electrical charge to drive a highly capacitive line leading to a sensor and set off its detection mechanism that determines whether a sufficient amount of charge is present in the capacitor to qualify as a “1”. This process takes 10 s of nanoseconds in modern DRAM chips. <strong>This is in sharp contrast with the sub-nanosecond clock cycle time of modern computing devices</strong>. </p>\n<h4>parallelism and memory access throughput</h4>\n<p>Because this is a very slow process relative to the desired data access speed (sub-nanosecond access per byte), modern DRAMs <strong>use parallelism to increase their rate of data access</strong>, commonly referred to as <em>memory access throughput</em>.</p>\n<h4>DRAM bursts</h4>\n<p>Each time a DRAM location is accessed, <strong>a range of consecutive locations that includes the requested location are actually accessed</strong>. </p>\n<p>Many sensors are provided in each DRAM chip and they work in parallel. Each senses the content of a bit within these consecutive locations. </p>\n<p>Once detected by the sensors, the data from all these consecutive locations can be transferred at very high-speed to the processor. These consecutive locations accessed and delivered are referred to as <strong>DRAM bursts</strong>. </p>\n<h4>motivation</h4>\n<p>If an application makes focused use of data from these bursts, the DRAMs can supply the data at a much higher rate than if a truly random sequence of locations were accessed.</p>\n<h2>Memory Coalescing</h2>\n<p>Current CUDA devices employ a technique that allows the programmers to achieve high global memory access efficiency by <strong>organizing memory accesses of threads into favorable patterns</strong>. </p>\n<h4>how?</h4>\n<ul>\n<li>\n<p>This technique takes advantage of the fact that <strong>threads in a warp execute the same instruction at any given point in time</strong>. </p>\n</li>\n<li>\n<p>The most favorable access pattern is achieved when all threads in a warp access consecutive global memory locations. </p>\n</li>\n<li>\n<p>When all threads in a warp execute a load instruction, the hardware detects whether they access consecutive global memory locations. If that’s the case, the hardware combines (<strong>coalesces</strong>) all these accesses into a consolidated access to consecutive DRAM locations. </p>\n</li>\n<li>\n<p>For example, for a given load instruction of a warp, if thread 0 accesses global memory location N2, thread 1 location N+1, thread 2 location N+2, and so on, all these accesses will be coalesced into a single request for consecutive locations when accessing the DRAMs. </p>\n</li>\n<li>\n<p>Such coalesced access allows the DRAMs to deliver data as a burst.</p>\n</li>\n</ul>\n<h4>how to effectively use the coalescing hardware?</h4>\n<p>Recall from <a href=\"/cuda2-warp\">The CUDA Parallel Programming Model - 2. Warps</a> that multidimensional array elements in CUDA are placed into the linearly addressed memory space according to the <strong>row-major</strong> convention. </p>\n<h5>matrix multiplication example</h5>\n<p>Say we have a kernel that computes <code class=\"language-text\">M x N</code>, where both M and N are 2D row-major\nEach thread accesses a row of the M array (picture A below) and a column of the N array (picture B below).</p>\n<ul>\n<li>\n<p>unfavorable data access pattern</p>\n<ul>\n<li>The picture below illustrates the data access pattern of the M array, where threads in a warp read adjacent rows. That is, during iteration 0, threads in a warp read element 0 of rows 0 through 31. During iteration 1, these same threads read element 1 of rows 0 through 31. None of the accesses will be coalesced.</li>\n<li><a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c34bd1d42541a79b84d3d7fec169ff8a/f3cbc/unfavorable.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 79.12087912087912%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAABYlAAAWJQFJUiTwAAAC5UlEQVQ4y3WU709SURjH+ZvyhVZTU8HfgrrqZa964ZpzrshQBK6mYPljvcnMH2kOEEEJXDHFNb0KISr4A0TRFolTa5Foxiu8fDv3qqSCZ/vsOTvnud99z32ec3hIMmKxWHwe/n2IWdqGlSUP1tf8WJx3Y2J8EvT0LNyuZdhnHVhd9sbzeVeFzsWO/h5g+5cP/p1lOD1TWNqwY8FLw+6ehM11imP5Mxfd63YEfqzhZ3gnUfCEOeHmi9+sqOjMQHV3ASpacyEeKETDWBkoUxkazOUclPl0TpnKIdblQGt7Ad5FV1cFH73NRHVPHipf8yEezEe9sRjSkaIEZKNCPB3OJoItpw4ZholzwkQ5wfmtCUgMAihMIijMQsg+lKB+NDlyo4gInjmMRqPJ6oL5r1ZyDD4REkFqJB+ygiRKk8DmiPVE0E4EHQ4H5ubm4HK5QNM0vGsehEN/MLdhQa02G5ShGLLhItRqCiHTFUKhT4QylECizYJuRgVeJBJBMBhEIBDA6uoq9vd3OYduzxhUnWno6MuBqusOatvSoezMREdvFtp6stB+gY5ektOZCtMEBZ7P5+MEQ6EQEdsn7OEoHMGC7yPkAxlQagvQrMmDaiifi01qguYybI58IB2GqSbw/H4/nE4n2KNbLBbicgXB7T24iEPlm5toJw7berPRyjojMRntfXwou4hDK3W5D7nWAcNFJynKE0MupOZS1JqEqIsjQp1ZxEV2nYXNeTwigPrLy/99eA5z1ocLW1ZIdLlQGEu5tpCNCCEn/VZPCiDVk8oahGRPxK1RxjI80wswZE8ieN7Yjs1PqFLfQo2ej5oRPip7M3FXkoJ7kht4oErF/foUPHx1G5JRsj8sQJUmDe9nGhOvHhM7PfLmrhv90wqobUpCMwZnmtBtodA3/hxqugV91ga8m2yE2t7M5fTTctDe0UTBq6/N1RE+OMT3QPDafd51T9flX8Fw5WJv1fkFOD4+PstjLuX+AwVM8AWhWiQRAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"unfavorable\"\n        title=\"\"\n        src=\"/static/c34bd1d42541a79b84d3d7fec169ff8a/d7711/unfavorable.png\"\n        srcset=\"/static/c34bd1d42541a79b84d3d7fec169ff8a/a695b/unfavorable.png 148w,\n/static/c34bd1d42541a79b84d3d7fec169ff8a/2f273/unfavorable.png 295w,\n/static/c34bd1d42541a79b84d3d7fec169ff8a/d7711/unfavorable.png 590w,\n/static/c34bd1d42541a79b84d3d7fec169ff8a/f3cbc/unfavorable.png 728w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n  </span>\n  </a></li>\n</ul>\n</li>\n<li>\n<p>favorable data access pattern\n<a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4fab173c0bc9c21451ad8321291049a0/2add1/favorable.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 494px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 116.59919028340082%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAABYlAAAWJQFJUiTwAAADKElEQVQ4y61VWU9aQRT25/SpTbTaxKUKuKCC8NJWH5omrjFtUmvACBcw0kSronWtMVaMNi0qOwKuxRgrIJqmkcTgUvvSN1PfrE1Yvs4dwGiBJq1O8nEuc7/zzZlz58xJAxnhSBihcIgiQp7Pf51j17+LjU8bcHs24bDPw+F0wOX6iO1tH7xbXiwuLsC15mLdEQwFqW+YIC0SiSBhhIE9fwDuDQ9Wl1xYW3djbXUdy+TZ49mBd9NH5/f3DhNc09ifg+9fsBGwwXu4AHfACd/xEraOluA7WsbO1xUEPhvh+7YK/54d/l0LvMcrdN57uIjNgIP6xEEFZ9wa1I1louF1PpqmOHjIZOHZOActc0WQfuBiVH0LzXPF6BjJQm9fOl7oiyHV8SCdKUwAFTTvDKFak40aNQ+SKT4qW3LwdLAI7XYxVAYhtD2ZYKxi9E1wMfzmPuQ2Mm+sgNJUAZUpauOggnpPPySzXDCzIkjflUJlqYDCKIDCJIR8ToAhdQYYiwia8QIMjeRCZhVByb43CmMQgDFE/8cEByCZ4aDNLIbSHCWwUFmEkEzzwTy/AwWJ6rKgwiC4EFMRH5U1GsQVQZVJdCEWj5CZLcewOh1yqyiJoIBsUwjpdCmatXzCTykovLAqYid77kJuThRk2OhIZA19PFTJc2iqkggKrwgqDeWY6MqA3JIkQnYHegGqOwvICeEl5vC/BImt7SpAY39hqhz+e4S1rwrwmMmDjOT7WoI0hyRvT9rzUCXLoQtcW7CNfJTqjnxUtmbTI3e9LbPHhog0DhSirot7AzmM8diSa6MH+wYivFp6sQgN3gFay7T0LhW6gi1+4qDtJpeDRYzetxx6OcjIRaFkF2N5xhguXw6z7l406XLJKmVoNfDRqudDpo9aub4E45230WIqQ/dYDvoH70FqLiPvSy54cS5rqaB9exIvTVXQ2OvRPV9zBRpbNd4PC9Bpr8Xo9CNMaB+g01mPHltNApcFEYwgFAohGAzS3pAAMs/2ivgIxeZScZP3lD/Gj9NTOJ1O0k88ODv7+Vcu3TIrmgq05xzsQ6vVQqfT4eTkJNrHwuGk/N+EUBpQSH2NtQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"favorable\"\n        title=\"\"\n        src=\"/static/4fab173c0bc9c21451ad8321291049a0/2add1/favorable.png\"\n        srcset=\"/static/4fab173c0bc9c21451ad8321291049a0/4a568/favorable.png 148w,\n/static/4fab173c0bc9c21451ad8321291049a0/5c55c/favorable.png 295w,\n/static/4fab173c0bc9c21451ad8321291049a0/2add1/favorable.png 494w\"\n        sizes=\"(max-width: 494px) 100vw, 494px\"\n      />\n  </span>\n  </a></p>\n</li>\n</ul>"
}
