{
  "expireTime": 9007200830646771000,
  "key": "transformer-remark-markdown-html-ast-22b75468dec89024fb4b618002e1b041-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": {
    "type": "root",
    "children": [
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "In the last post, we saw how full concurrency can be achieved amongst streams. Here Iâ€™d like to talk about how CUDA operations from different streams may also be interleaved, which is another programming model often used to effect concurrency.",
            "position": {
              "start": { "line": 2, "column": 1, "offset": 1 },
              "end": { "line": 2, "column": 244, "offset": 244 }
            }
          }
        ],
        "position": {
          "start": { "line": 2, "column": 1, "offset": 1 },
          "end": { "line": 2, "column": 244, "offset": 244 }
        }
      }
    ],
    "position": {
      "start": { "line": 1, "column": 1, "offset": 0 },
      "end": { "line": 2, "column": 244, "offset": 244 }
    }
  }
}
