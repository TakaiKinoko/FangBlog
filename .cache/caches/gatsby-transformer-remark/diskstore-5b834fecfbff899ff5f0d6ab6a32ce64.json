{
  "expireTime": 9007200830739094000,
  "key": "transformer-remark-markdown-ast-4925a4605a10dbb4cf0afea17c905e62-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": {
    "type": "root",
    "children": [
      {
        "type": "paragraph",
        "children": [
          {
            "type": "text",
            "value": "There’s an intrinsic tradeoff in the use of device memories in CUDA: the ",
            "position": {
              "start": { "line": 2, "column": 1, "offset": 1 },
              "end": { "line": 2, "column": 74, "offset": 74 },
              "indent": []
            }
          },
          {
            "type": "strong",
            "children": [
              {
                "type": "text",
                "value": "global memory",
                "position": {
                  "start": { "line": 2, "column": 76, "offset": 76 },
                  "end": { "line": 2, "column": 89, "offset": 89 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 2, "column": 74, "offset": 74 },
              "end": { "line": 2, "column": 91, "offset": 91 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": " is large but slow, whereas the ",
            "position": {
              "start": { "line": 2, "column": 91, "offset": 91 },
              "end": { "line": 2, "column": 123, "offset": 123 },
              "indent": []
            }
          },
          {
            "type": "strong",
            "children": [
              {
                "type": "text",
                "value": "shared memory",
                "position": {
                  "start": { "line": 2, "column": 125, "offset": 125 },
                  "end": { "line": 2, "column": 138, "offset": 138 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 2, "column": 123, "offset": 123 },
              "end": { "line": 2, "column": 140, "offset": 140 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": " is small but fast.",
            "position": {
              "start": { "line": 2, "column": 140, "offset": 140 },
              "end": { "line": 2, "column": 159, "offset": 159 },
              "indent": []
            }
          }
        ],
        "position": {
          "start": { "line": 2, "column": 1, "offset": 1 },
          "end": { "line": 2, "column": 159, "offset": 159 },
          "indent": []
        }
      },
      {
        "type": "paragraph",
        "children": [
          {
            "type": "text",
            "value": "(To recap on the memory hierarchy: ",
            "position": {
              "start": { "line": 4, "column": 1, "offset": 161 },
              "end": { "line": 4, "column": 36, "offset": 196 },
              "indent": []
            }
          },
          {
            "type": "link",
            "title": null,
            "url": "/cuda1",
            "children": [
              {
                "type": "text",
                "value": "The CUDA Parallel Programming Model - 1. Concepts",
                "position": {
                  "start": { "line": 4, "column": 37, "offset": 197 },
                  "end": { "line": 4, "column": 86, "offset": 246 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 4, "column": 36, "offset": 196 },
              "end": { "line": 4, "column": 95, "offset": 255 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": ", on how to specify memories for variables: ",
            "position": {
              "start": { "line": 4, "column": 95, "offset": 255 },
              "end": { "line": 4, "column": 139, "offset": 299 },
              "indent": []
            }
          },
          {
            "type": "link",
            "title": null,
            "url": "/cudaProg2-Variables",
            "children": [
              {
                "type": "text",
                "value": "CUDA Programming - 2. CUDA Variable Type Qualifiers",
                "position": {
                  "start": { "line": 4, "column": 140, "offset": 300 },
                  "end": { "line": 4, "column": 191, "offset": 351 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 4, "column": 139, "offset": 299 },
              "end": { "line": 4, "column": 214, "offset": 374 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": ".)",
            "position": {
              "start": { "line": 4, "column": 214, "offset": 374 },
              "end": { "line": 4, "column": 216, "offset": 376 },
              "indent": []
            }
          }
        ],
        "position": {
          "start": { "line": 4, "column": 1, "offset": 161 },
          "end": { "line": 4, "column": 216, "offset": 376 },
          "indent": []
        }
      },
      {
        "type": "paragraph",
        "children": [
          {
            "type": "text",
            "value": "A common strategy to reduce memory traffic is to partition the ",
            "position": {
              "start": { "line": 6, "column": 1, "offset": 378 },
              "end": { "line": 6, "column": 64, "offset": 441 },
              "indent": []
            }
          },
          {
            "type": "strong",
            "children": [
              {
                "type": "text",
                "value": "data",
                "position": {
                  "start": { "line": 6, "column": 66, "offset": 443 },
                  "end": { "line": 6, "column": 70, "offset": 447 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 64, "offset": 441 },
              "end": { "line": 6, "column": 72, "offset": 449 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": " into subsets called ",
            "position": {
              "start": { "line": 6, "column": 72, "offset": 449 },
              "end": { "line": 6, "column": 93, "offset": 470 },
              "indent": []
            }
          },
          {
            "type": "strong",
            "children": [
              {
                "type": "text",
                "value": "tiles",
                "position": {
                  "start": { "line": 6, "column": 95, "offset": 472 },
                  "end": { "line": 6, "column": 100, "offset": 477 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 93, "offset": 470 },
              "end": { "line": 6, "column": 102, "offset": 479 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": " so that ",
            "position": {
              "start": { "line": 6, "column": 102, "offset": 479 },
              "end": { "line": 6, "column": 111, "offset": 488 },
              "indent": []
            }
          },
          {
            "type": "strong",
            "children": [
              {
                "type": "text",
                "value": "each tile fits into the shared memory",
                "position": {
                  "start": { "line": 6, "column": 113, "offset": 490 },
                  "end": { "line": 6, "column": 150, "offset": 527 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 111, "offset": 488 },
              "end": { "line": 6, "column": 152, "offset": 529 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": ". An important criterion is that kernel computation on these tiles can be performed independently of each other. Note that ",
            "position": {
              "start": { "line": 6, "column": 152, "offset": 529 },
              "end": { "line": 6, "column": 275, "offset": 652 },
              "indent": []
            }
          },
          {
            "type": "strong",
            "children": [
              {
                "type": "text",
                "value": "not",
                "position": {
                  "start": { "line": 6, "column": 277, "offset": 654 },
                  "end": { "line": 6, "column": 280, "offset": 657 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 6, "column": 275, "offset": 652 },
              "end": { "line": 6, "column": 282, "offset": 659 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": " all data structures can be partitioned into tiles given an arbitrary kernel function.",
            "position": {
              "start": { "line": 6, "column": 282, "offset": 659 },
              "end": { "line": 6, "column": 368, "offset": 745 },
              "indent": []
            }
          }
        ],
        "position": {
          "start": { "line": 6, "column": 1, "offset": 378 },
          "end": { "line": 6, "column": 368, "offset": 745 },
          "indent": []
        }
      },
      {
        "type": "paragraph",
        "children": [
          {
            "type": "text",
            "value": "The term “tile” draws on the analogy that a large wall (i.e., the global memory data) can be covered by tiles (i.e., subsets that each can fit into the shared memory).",
            "position": {
              "start": { "line": 8, "column": 1, "offset": 747 },
              "end": { "line": 8, "column": 168, "offset": 914 },
              "indent": []
            }
          }
        ],
        "position": {
          "start": { "line": 8, "column": 1, "offset": 747 },
          "end": { "line": 8, "column": 168, "offset": 914 },
          "indent": []
        }
      },
      {
        "type": "paragraph",
        "children": [
          {
            "type": "text",
            "value": "To illustrate the concept of tiling, we use the example from ",
            "position": {
              "start": { "line": 10, "column": 1, "offset": 916 },
              "end": { "line": 10, "column": 62, "offset": 977 },
              "indent": []
            }
          },
          {
            "type": "link",
            "title": null,
            "url": "/cudaProg1-matrixmult",
            "children": [
              {
                "type": "text",
                "value": "CUDA Programming - 1. Matrix Multiplication",
                "position": {
                  "start": { "line": 10, "column": 63, "offset": 978 },
                  "end": { "line": 10, "column": 106, "offset": 1021 },
                  "indent": []
                }
              }
            ],
            "position": {
              "start": { "line": 10, "column": 62, "offset": 977 },
              "end": { "line": 10, "column": 130, "offset": 1045 },
              "indent": []
            }
          },
          {
            "type": "text",
            "value": ". ",
            "position": {
              "start": { "line": 10, "column": 130, "offset": 1045 },
              "end": { "line": 10, "column": 132, "offset": 1047 },
              "indent": []
            }
          }
        ],
        "position": {
          "start": { "line": 10, "column": 1, "offset": 916 },
          "end": { "line": 10, "column": 132, "offset": 1047 },
          "indent": []
        }
      }
    ],
    "position": {
      "start": { "line": 1, "column": 1, "offset": 0 },
      "end": { "line": 10, "column": 132, "offset": 1047 }
    }
  }
}
