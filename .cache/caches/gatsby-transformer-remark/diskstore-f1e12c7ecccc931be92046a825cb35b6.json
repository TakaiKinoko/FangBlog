{"expireTime":9007200830663894000,"key":"transformer-remark-markdown-html-46b950569d8e33caa8ebaca31dee6d1f-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-","val":"<p>Motivated by a CUDA puzzle I tried to solve today, I’d like to talk more about resource assignment es</p>\n<h2>A Puzzle</h2>\n<h3>problem</h3>\n<p>Adding two big arrays element-wise.</p>\n<h3>settings</h3>\n<ul>\n<li>Suppose a GPU has 8 SMs</li>\n<li>Each SM has 32 SPs</li>\n<li>Warp size is 16, instead of 32</li>\n<li>kernel adds one element from each array together</li>\n</ul>\n<h3>questions</h3>\n<p>Say if we were to compute everything sequentially, it takes time <code class=\"language-text\">t</code> to finish.</p>\n<h4>scenario 1</h4>\n<p>Assume that 256 threads are enough to keep all SPs in the SM busy all the time. What is the amount of time it’d take to perform the computation for <strong>one block of 1024</strong> threads? </p>\n<h4>scenario 2</h4>\n<p>What if we use <strong>two blocks</strong> of <strong>512 threads</strong> each?</p>\n<h2>CUDA Resource Assignment</h2>"}