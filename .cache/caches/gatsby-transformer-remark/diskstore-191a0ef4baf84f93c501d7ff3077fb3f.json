{
  "expireTime": 9007200830646833000,
  "key": "transformer-remark-markdown-html-ast-8fa6ac419b7101073b8868e275d6447c-gatsby-remark-imagesgatsby-remark-responsive-iframegatsby-remark-prismjsgatsby-remark-copy-linked-filesgatsby-remark-smartypantsgatsby-remark-reading-time-",
  "val": {
    "type": "root",
    "children": [
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "In the last post, we saw how full concurrency can be achieved amongst streams. Here Iâ€™d like to talk about how CUDA operations from different streams may also be ",
            "position": {
              "start": { "line": 2, "column": 1, "offset": 1 },
              "end": { "line": 2, "column": 163, "offset": 163 }
            }
          },
          {
            "type": "element",
            "tagName": "strong",
            "properties": {},
            "children": [
              {
                "type": "text",
                "value": "interleaved",
                "position": {
                  "start": { "line": 2, "column": 165, "offset": 165 },
                  "end": { "line": 2, "column": 176, "offset": 176 }
                }
              }
            ],
            "position": {
              "start": { "line": 2, "column": 163, "offset": 163 },
              "end": { "line": 2, "column": 178, "offset": 178 }
            }
          },
          {
            "type": "text",
            "value": ", which is another programming model often used to effect concurrency.",
            "position": {
              "start": { "line": 2, "column": 178, "offset": 178 },
              "end": { "line": 2, "column": 248, "offset": 248 }
            }
          }
        ],
        "position": {
          "start": { "line": 2, "column": 1, "offset": 1 },
          "end": { "line": 2, "column": 248, "offset": 248 }
        }
      },
      { "type": "text", "value": "\n" },
      {
        "type": "element",
        "tagName": "p",
        "properties": {},
        "children": [
          {
            "type": "text",
            "value": "(beyond multi-threaded parallelism)\nCUDA Kernel <<<>>>\ncudaMemcpyAsync (HostToDevice)\ncudaMemcpyAsync (DeviceToHost)\nOperations on the CPU",
            "position": {
              "start": { "line": 5, "column": 1, "offset": 251 },
              "end": { "line": 9, "column": 22, "offset": 389 }
            }
          }
        ],
        "position": {
          "start": { "line": 5, "column": 1, "offset": 251 },
          "end": { "line": 9, "column": 22, "offset": 389 }
        }
      }
    ],
    "position": {
      "start": { "line": 1, "column": 1, "offset": 0 },
      "end": { "line": 9, "column": 22, "offset": 389 }
    }
  }
}
